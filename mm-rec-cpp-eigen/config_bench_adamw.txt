# Benchmark Config: AdamW (Baseline)
vocab_size=16
hidden_dim=64
mem_dim=64
ffn_dim=128
num_layers=1
num_experts=1
top_k=1

batch_size=8
max_seq_len=32
learning_rate=0.005
optimizer_type=adamw  # <--- BASELINE
weight_decay=0.01
max_iterations=30

hard_threshold=300
easy_threshold=1.0

checkpoint_path=bench_adamw.bin
