# Kernel-Small (Realistic Training - 2M params)

# REDUCED vocab for faster convergence
vocab_size=1000
hidden_dim=128
mem_dim=128
ffn_dim=384
num_layers=3
num_experts=2
top_k=1

# Training (SAFER LR to prevent gradient explosion)
optimizer_type=adamw
learning_rate=0.005
warmup_steps=10
total_steps=100
weight_decay=0.01
beta1=0.9
beta2=0.999
batch_size=8
max_seq_len=128

uboo_weight=0.5
checkpoint_path=kernel_small.bin
vocab_path=vocab.txt
