================================================================================
MM-Rec 100M - Real Training
================================================================================
ğŸ–¥ï¸  Device: cpu
ğŸ“… Start time: 2025-12-09 18:58:33
ğŸ“¦ Loading data from ./data/chat_data_real.jsonl... âœ… 1400 conversations

ğŸ”¤ Initializing tokenizer... âœ… (vocab=100277)
ğŸ¤– Initializing model... âœ… (148,788,480 params)
ğŸ“ Initializing trainer... âœ…

ğŸš€ Starting REAL training:
   Steps: 10
   Batch size: 1
   Max length: 128
   Learning rate: 1e-05
   Warmup steps: 500
================================================================================
ğŸš€ Training |                                                                                          | 0/10 [00:00<?] 
================================================================================
ğŸ“Š Training Started - Real-time Updates
================================================================================


ğŸ”„ Step 1/10 - Processing...
  ğŸ“ Preparing input...
  âœ… Input prepared: shape=torch.Size([1, 128]), valid_labels=128/128
  ğŸ”„ Running forward pass...
  âœ… Forward done: logits shape=torch.Size([1, 128, 100277])
  ğŸ“Š Computing loss...
  âœ… Loss computed: 11.595111
  â¬…ï¸  Running backward pass...
  âœ… Backward done: grad_norm=11.4833, params_with_grad=967
  âœ… Optimizer step completed
âœ… Step 1 completed: loss=11.5951, time=70.92s
ğŸš€ Training |                              | 0/10 [01:10<?] , loss=11.5951, avg=11.5951, ppl=inf, lr=1.02e-06, spd=0.0/s                                                                                                                        ğŸš€ Training |                              | 0/10 [01:10<?] , loss=11.5951, avg=11.5951, ppl=inf, lr=1.02e-06, spd=0.0/sğŸš€ Training |â–ˆâ–ˆâ–Œ                       | 1/10 [01:10<10:38] , loss=11.5951, avg=11.5951, ppl=inf, lr=1.02e-06, spd=0.0/sğŸ“ˆ Step 1/10 | Loss: 11.5951 (avg: 11.5951) | PPL: inf | LR: 1.02e-06 | Speed: 0.0 steps/s | Time: 1.2m (ETA: 10.6m)

ğŸ”„ Step 2/10 - Processing...
  ğŸ“ Preparing input...
  âœ… Input prepared: shape=torch.Size([1, 128]), valid_labels=128/128
  ğŸ”„ Running forward pass...
  âœ… Forward done: logits shape=torch.Size([1, 128, 100277])
  ğŸ“Š Computing loss...
  âœ… Loss computed: 11.629010
  â¬…ï¸  Running backward pass...
  âœ… Backward done: grad_norm=7.8857, params_with_grad=967
  âœ… Optimizer step completed
âœ… Step 2 completed: loss=11.6290, time=67.67s
ğŸš€ Training |â–ˆâ–ˆâ–Œ                       | 1/10 [02:18<10:38] , loss=11.6290, avg=11.6121, ppl=inf, lr=1.04e-06, spd=0.0/s                                                                                                                        ğŸš€ Training |â–ˆâ–ˆâ–Œ                       | 1/10 [02:18<10:38] , loss=11.6290, avg=11.6121, ppl=inf, lr=1.04e-06, spd=0.0/sğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 2/10 [02:18<09:12] , loss=11.6290, avg=11.6121, ppl=inf, lr=1.04e-06, spd=0.0/sğŸ“ˆ Step 2/10 | Loss: 11.6290 (avg: 11.6121) | PPL: inf | LR: 1.04e-06 | Speed: 0.0 steps/s | Time: 2.3m (ETA: 9.0m)

ğŸ”„ Step 3/10 - Processing...
  ğŸ“ Preparing input...
  âœ… Input prepared: shape=torch.Size([1, 128]), valid_labels=128/128
  ğŸ”„ Running forward pass...
  âœ… Forward done: logits shape=torch.Size([1, 128, 100277])
  ğŸ“Š Computing loss...
  âœ… Loss computed: 11.457298
  â¬…ï¸  Running backward pass...
  âœ… Backward done: grad_norm=19.4180, params_with_grad=967
  âœ… Optimizer step completed
âœ… Step 3 completed: loss=11.4573, time=57.81s
ğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 2/10 [03:16<09:12] , loss=11.4573, avg=11.5605, ppl=inf, lr=1.05e-06, spd=0.0/s                                                                                                                        ğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 2/10 [03:16<09:12] , loss=11.4573, avg=11.5605, ppl=inf, lr=1.05e-06, spd=0.0/sğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 3/10 [03:16<07:27] , loss=11.4573, avg=11.5605, ppl=inf, lr=1.05e-06, spd=0.0/sğŸ“ˆ Step 3/10 | Loss: 11.4573 (avg: 11.5605) | PPL: inf | LR: 1.05e-06 | Speed: 0.0 steps/s | Time: 3.3m (ETA: 6.7m)

ğŸ”„ Step 4/10 - Processing...
  ğŸ“ Preparing input...
  âœ… Input prepared: shape=torch.Size([1, 128]), valid_labels=128/128
  ğŸ”„ Running forward pass...
  âœ… Forward done: logits shape=torch.Size([1, 128, 100277])
  ğŸ“Š Computing loss...
  âœ… Loss computed: 11.376825
  â¬…ï¸  Running backward pass...
  âœ… Backward done: grad_norm=24.2206, params_with_grad=967
  âœ… Optimizer step completed
âœ… Step 4 completed: loss=11.3768, time=59.80s
ğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 3/10 [04:16<07:27] , loss=11.3768, avg=11.5146, ppl=inf, lr=1.07e-06, spd=0.0/s                                                                                                                        ğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 3/10 [04:16<07:27] , loss=11.3768, avg=11.5146, ppl=inf, lr=1.07e-06, spd=0.0/sğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 4/10 [04:16<06:13] , loss=11.3768, avg=11.5146, ppl=inf, lr=1.07e-06, spd=0.0/sğŸ“ˆ Step 4/10 | Loss: 11.3768 (avg: 11.5146) | PPL: inf | LR: 1.07e-06 | Speed: 0.0 steps/s | Time: 4.3m (ETA: 6.0m)

ğŸ”„ Step 5/10 - Processing...
  ğŸ“ Preparing input...
  âœ… Input prepared: shape=torch.Size([1, 128]), valid_labels=128/128
  ğŸ”„ Running forward pass...
  âœ… Forward done: logits shape=torch.Size([1, 128, 100277])
  ğŸ“Š Computing loss...
  âœ… Loss computed: 11.437911
  â¬…ï¸  Running backward pass...
  âœ… Backward done: grad_norm=19.3589, params_with_grad=967
  âœ… Optimizer step completed
âœ… Step 5 completed: loss=11.4379, time=92.50s
ğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 4/10 [05:48<06:13] , loss=11.4379, avg=11.4992, ppl=inf, lr=1.09e-06, spd=0.0/s                                                                                                                        ğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 4/10 [05:48<06:13] , loss=11.4379, avg=11.4992, ppl=inf, lr=1.09e-06, spd=0.0/s                                                                                                                        ğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 4/10 [05:50<06:13] , loss=11.4379, avg=11.4992, ppl=inf, lr=1.09e-06, spd=0.0/sğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 5/10 [05:50<06:09] , loss=11.4379, avg=11.4992, ppl=inf, lr=1.09e-06, spd=0.0/s  ğŸ“ Preparing input...
  âœ… Input prepared: shape=torch.Size([1, 128]), valid_labels=128/128
  ğŸ”„ Running forward pass...
  âœ… Forward done: logits shape=torch.Size([1, 128, 100277])
  ğŸ“Š Computing loss...
  âœ… Loss computed: 11.438311
  â¬…ï¸  Running backward pass...
  âœ… Backward done: grad_norm=13.0906, params_with_grad=967
  âœ… Optimizer step completed
ğŸ“ˆ Step 5/10 | Loss: 11.4379 (avg: 11.4992) | PPL: inf | LR: 1.09e-06 | Speed: 0.0 steps/s | Time: 5.8m (ETA: 7.7m)

ğŸ’¾ Checkpoint 5 saved!
   Loss: 11.4379 | Avg Loss: 11.4992 | Min Loss: 11.3768
   Avg PPL: inf | Steps/sec: 0.01
   File: checkpoints_real/checkpoint_step_5.pt

âœ… Step 6 completed: loss=11.4383, time=56.77s
ğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 5/10 [06:47<06:09] , loss=11.4383, avg=11.4891, ppl=inf, lr=1.11e-06, spd=0.0/s                                                                                                                        ğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 5/10 [06:47<06:09] , loss=11.4383, avg=11.4891, ppl=inf, lr=1.11e-06, spd=0.0/sğŸš€ Training |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 6/10 [06:47<04:32] , loss=11.4383, avg=11.4891, ppl=inf, lr=1.11e-06, spd=0.0/s  ğŸ“ Preparing input...
  âœ… Input prepared: shape=torch.Size([1, 128]), valid_labels=128/128
  ğŸ”„ Running forward pass...
  âœ… Forward done: logits shape=torch.Size([1, 128, 100277])
  ğŸ“Š Computing loss...
  âœ… Loss computed: 11.290895
  â¬…ï¸  Running backward pass...
