# MM-Rec Implementation Prompts
## LLM-Assisted Development Guide

Bu dokÃ¼man, MM-Rec projesinin eksik bileÅŸenlerini LLM (BÃ¼yÃ¼k Dil Modeli) ile adÄ±m adÄ±m geliÅŸtirmek iÃ§in hazÄ±rlanmÄ±ÅŸ detaylÄ± prompt'larÄ± iÃ§erir.

Her prompt, bir bileÅŸenin tam implementasyonu iÃ§in gerekli tÃ¼m bilgileri iÃ§erir.

---

## ğŸ¯ Faz 1: Ã‡ekirdek BileÅŸenler (Core Components)

### 1. Memory State Management (Bellek Durum YÃ¶netimi)

**Dosya:** `mm_rec/core/memory_state.py`

**Prompt:**

```
Åu an MM-Rec modelinin temel veri yapÄ±larÄ±nÄ± oluÅŸturuyoruz. LÃ¼tfen mm_rec/core/memory_state.py dosyasÄ±nÄ± oluÅŸtur. Bu dosya, modelin kÄ±sa ve uzun vadeli belleklerini yÃ¶netmelidir.

**Gereksinimler:**

1. **MemoryBank SÄ±nÄ±fÄ±:** Tek bir bellek birimini (short-term veya long-term) temsil eden `MemoryBank` adÄ±nda bir Python/PyTorch sÄ±nÄ±fÄ± oluÅŸtur.

   * **__init__**: `k_dim`, `v_dim`, `num_slots` (bellek yuvasÄ± sayÄ±sÄ±) ve `dtype` (varsayÄ±lan olarak `torch.bfloat16`) parametrelerini almalÄ±.
   * **self.k (Key)** ve **self.v (Value)** olmak Ã¼zere iki PyTorch tensÃ¶rÃ¼nÃ¼ baÅŸlatmalÄ±. Bunlar `k` ve `v` boyutlarÄ±na ve `num_slots` sayÄ±sÄ±na sahip olmalÄ±. TensÃ¶rler CPU veya GPU'da tutulabilir (cihaz parametresi eklenebilir).
   * **Fonksiyon**: `initialize_bank(self, num_slots)`: BankayÄ± sÄ±fÄ±r tensÃ¶rlerle veya Gaussian daÄŸÄ±lÄ±mÄ±yla baÅŸlatmalÄ±.

2. **MemoryState SÄ±nÄ±fÄ±:** Modelin genel bellek durumunu yÃ¶neten `MemoryState` adÄ±nda bir sÄ±nÄ±f oluÅŸtur.

   * **__init__**: `short_term_config` ve `long_term_config` olmak Ã¼zere iki ayrÄ± yapÄ±landÄ±rma sÃ¶zlÃ¼ÄŸÃ¼nÃ¼ almalÄ±.
   * **self.short_term** ve **self.long_term** adÄ±nda iki `MemoryBank` Ã¶rneÄŸini baÅŸlatmalÄ±.
   * **Fonksiyon**: `get_state(self, bank_type: str) -> tuple[torch.Tensor, torch.Tensor]`: Belirtilen banka tipinin (Ã¶rneÄŸin 'short') `(k, v)` tensÃ¶rlerini dÃ¶ndÃ¼rmeli.
   * **Fonksiyon**: `update_state(self, bank_type: str, new_k: torch.Tensor, new_v: torch.Tensor)`: Belirtilen bankanÄ±n `k` ve `v` tensÃ¶rlerini yeni tensÃ¶rlerle deÄŸiÅŸtirmeli.
   * **Fonksiyon**: `to_device(self, device)`: TÃ¼m bellek bankalarÄ±ndaki tensÃ¶rleri belirtilen cihaza taÅŸÄ±malÄ±.

**Ek Notlar:**
- MemoryBank ve MemoryState sÄ±nÄ±flarÄ± PyTorch'un `nn.Module`'Ã¼nden tÃ¼retilmeli (eÄŸer parametre iÃ§eriyorsa)
- Short-term memory: `[batch, seq_len, hidden_dim]` formatÄ±nda
- Long-term memory: `[batch, num_memories, M, mem_dim]` formatÄ±nda (M << seq_len)
- Referans: ENGINEERING_OUTPUTS.md bÃ¶lÃ¼m 4.1 ve CODE_STRUCTURE.md
```

---

### 2. MDI (Memory Decay/Integration)

**Dosya:** `mm_rec/core/mdi.py`

**Prompt:**

```
MM-Rec modelinin bellek bozunumu ve entegrasyon mantÄ±ÄŸÄ±nÄ± uygulamamÄ±z gerekiyor. LÃ¼tfen mm_rec/core/mdi.py dosyasÄ±nÄ± oluÅŸtur. Bu modÃ¼l, Associative Scan'dan gelen mantÄ±ÄŸÄ± kullanarak bellek gÃ¼ncelleme kapÄ±larÄ±nÄ± (gated integration) yÃ¶netecek.

**Gereksinimler:**

1. **MemoryDecayIntegration (MDI) SÄ±nÄ±fÄ±:** Bir PyTorch `nn.Module` olarak `MemoryDecayIntegration` adÄ±nda bir sÄ±nÄ±f oluÅŸtur. Bu sÄ±nÄ±f, modelin bir katmanÄ±ndaki (layer) bellek gÃ¼ncelleme mekanizmasÄ±nÄ± temsil etmelidir.

   * **__init__**: `model_dim` ve `inner_dim` parametrelerini almalÄ±.
   * **self.W_g (Gating AÄŸÄ±rlÄ±ÄŸÄ±)**: Yeni gelen girdi (`z_t`) ile eski durumun (`h_{t-1}`) ne kadarÄ±nÄ±n birleÅŸtirileceÄŸini kontrol eden bir lineer katman (`nn.Linear`) tanÄ±mla.
   * **self.W_gamma (Decay AÄŸÄ±rlÄ±ÄŸÄ±)**: Bozunum katsayÄ±sÄ± Î³'yÄ± Ã¶ÄŸrenebilmek iÃ§in `model_dim`'den `inner_dim`'e bir lineer katman tanÄ±mla.
   * **self.W_context (ModÃ¼lasyon AÄŸÄ±rlÄ±ÄŸÄ±)**: Gated entegrasyonu kontekste baÄŸÄ±mlÄ± hale getirmek iÃ§in bir lineer katman tanÄ±mla (opsiyonel).

2. **Ä°leri GeÃ§iÅŸ (Forward) Metodu:** `forward(self, z_t: torch.Tensor, h_prev: torch.Tensor, context: torch.Tensor = None) -> tuple[torch.Tensor, torch.Tensor]` metodunu oluÅŸtur.

   * **Gated Entegrasyon HesaplamasÄ± (z_t ve h_prev)**:
     * $g = \sigma(W_g \cdot [\text{z\_t}, \text{h\_prev}])$ (Burada $\sigma$ sigmoid fonksiyonudur ve $[\cdot, \cdot]$ birleÅŸtirmedir). Bu kapÄ±, $\mathbf{g}$ adÄ±yla yeni ve eski bilginin aÄŸÄ±rlÄ±ÄŸÄ±nÄ± belirleyecek.
     * Yeni durum adayÄ±: $\tilde{h} = (1 - g) \odot h_{\text{prev}} + g \odot z_t$.

   * **Bozunum KatsayÄ±sÄ± (Î³) HesaplamasÄ±**:
     * $\gamma = \sigma(W_{\gamma} \cdot z_t)$

   * **Geri DÃ¶nÃ¼ÅŸ**: Hesaplanan `h_new` (yeni durum) ve $\gamma$ tensÃ¶rlerini dÃ¶ndÃ¼r.

**Ek Notlar:**
- Core Formula: `h_t = z_t âŠ™ Ïƒ(W_g h_{t-1}) + Î³ âŠ™ h_{t-1}` ile uyumlu olmalÄ±
- Referans: CORE_FORMULA_SPEC.md ve IMPLEMENTATION_SPEC.md bÃ¶lÃ¼m 3
- Î³ deÄŸerleri [1e-6, 1-1e-6] aralÄ±ÄŸÄ±nda clamp edilmeli
```

---

### 3. HDS (Hierarchical Data Structure)

**Dosya:** `mm_rec/core/hds.py`

**Prompt:**

```
MM-Rec modelinin en karmaÅŸÄ±k kÄ±smÄ± olan HiyerarÅŸik Veri YapÄ±sÄ±'nÄ± (HDS) uygulamamÄ±z gerekiyor. LÃ¼tfen mm_rec/core/hds.py dosyasÄ±nÄ± oluÅŸtur. Bu yapÄ±, bellek eriÅŸimini O(M) karmaÅŸÄ±klÄ±ÄŸÄ± ile yapabilmek iÃ§in kritiktir.

**Gereksinimler:**

1. **HDS SÄ±nÄ±fÄ±:** Bir PyTorch `nn.Module` olarak `HierarchicalDataStructure` (HDS) adÄ±nda bir sÄ±nÄ±f oluÅŸtur.

   * **__init__**: `memory_state: MemoryState`, `num_levels: int = 3` ve `level_dims: list` (her seviyenin bellek yuvasÄ± sayÄ±sÄ±) parametrelerini almalÄ±.
   * **self.levels** adÄ±nda bir liste veya sÃ¶zlÃ¼k tutmalÄ±.

2. **HiyerarÅŸi Ä°nÅŸa Fonksiyonu:** `construct_hierarchy(self, state: MemoryState)` metodunu oluÅŸtur.

   * Bu fonksiyon, `MemoryState` iÃ§indeki `long_term` belleÄŸi kullanarak bir dizi havuzlama (pooling) iÅŸlemi ile hiyerarÅŸiyi sembolik olarak inÅŸa etmeli.
   * **BasitleÅŸtirme**: GerÃ§ek havuzlama yerine, her seviye iÃ§in `long_term` Key/Value tensÃ¶rlerinin bir alt kÃ¼mesini temsil eden tensÃ¶rler yarat. Ã–rneÄŸin, Level 1'in belleÄŸi, Level 0'Ä±n belleÄŸinin (Long-term) bir Ã¶zetidir.
   * **AmaÃ§**: Her seviyedeki bellek yuvalarÄ±nÄ± (slots) PyTorch tensÃ¶rleri olarak temsil etmek.

3. **O(M) Sorgulama Fonksiyonu:** `query_memory(self, query: torch.Tensor, level: int = -1)` metodunu oluÅŸtur.

   * Bu, `Multi-Memory Attention` bileÅŸeninin kullanacaÄŸÄ± hÄ±zlÄ± eriÅŸim arayÃ¼zÃ¼dÃ¼r.
   * **query**: GeÃ§erli durum temsilini (h_t) alÄ±r.
   * **level**: Hangi hiyerarÅŸi seviyesinin sorgulanacaÄŸÄ±nÄ± belirtir (varsayÄ±lan olarak en Ã¼st seviye, en kÃ¼Ã§Ã¼k bellek).
   * **Uygulama**: Belirtilen seviyedeki bellek bankasÄ±nÄ±n **Key** tensÃ¶rÃ¼nÃ¼ almalÄ± ve `query` ile bu Key'ler arasÄ±nda dikkat skorlarÄ±nÄ± hesaplamak iÃ§in bir hazÄ±rlÄ±k yapmalÄ±dÄ±r.
   * **Geri DÃ¶nÃ¼ÅŸ**: Sorgulanacak bellek Key ve Value tensÃ¶rlerini (`k_level`, `v_level`) dÃ¶ndÃ¼rmeli.

**Ek Notlar:**
- Hierarchy levels: Level 0 (token), Level 1 (block), Level 2 (global), Level 3 (long-term M)
- Access cost: O(M), not O(N) where N is sequence length
- Referans: IMPLEMENTATION_SPEC.md bÃ¶lÃ¼m 2 ve TECHNICAL_REQUIREMENTS.md
```

---

## ğŸ—ï¸ Faz 2: Blok Entegrasyonu

### 4. MM-Rec Block

**Dosya:** `mm_rec/blocks/mm_rec_block.py`

**Prompt:**

```
TÃ¼m temel bileÅŸenleri (Associative Scan, MDI, HDS) birleÅŸtiren ana katman yapÄ±sÄ±nÄ± oluÅŸturmamÄ±z gerekiyor. LÃ¼tfen mm_rec/blocks/mm_rec_block.py dosyasÄ±nÄ± oluÅŸtur ve MMRecBlock sÄ±nÄ±fÄ±nÄ± PyTorch nn.Module olarak tanÄ±mla.

**Gereksinimler:**

1. **MMRecBlock SÄ±nÄ±fÄ±:** PyTorch `nn.Module` olarak `MMRecBlock` sÄ±nÄ±fÄ±nÄ± oluÅŸtur.

   * **__init__**: `model_dim`, `inner_dim`, `num_heads`, `num_memories`, `mem_dim` gibi parametreleri almalÄ±.
   * **BaÄŸÄ±mlÄ±lÄ±klar**: Daha Ã¶nce oluÅŸturulan `AssociativeScanExponential` (`from mm_rec.core.associative_scan_triton import associative_scan_exponential`), `MemoryDecayIntegration` ve `HierarchicalDataStructure` Ã¶rneklerini sÄ±nÄ±f Ã¼yeleri olarak baÅŸlatmalÄ±.
   * **Lineer Katmanlar**: Gerekli transformasyonlar iÃ§in `nn.Linear` katmanlarÄ± (`W_q`, `W_k`, `W_v`, `W_z` - z_t iÃ§in) tanÄ±mlanmalÄ±.
   * **Normalization**: RMSNorm katmanlarÄ± eklenmeli.

2. **Ä°leri GeÃ§iÅŸ (Forward) Metodu:** `forward(self, x: torch.Tensor, state: MemoryState) -> tuple[torch.Tensor, MemoryState]` metodunu oluÅŸtur. Bu metod, tek bir MM-Rec katmanÄ±nÄ±n tÃ¼m 7 adÄ±mÄ±nÄ± sÄ±ralamalÄ±dÄ±r.

   * **AdÄ±mlar:**

     a. **Query, Key, Value, Z TransformasyonlarÄ±**: GiriÅŸ `x`'ten `q`, `k`, `v`, `z_t` tensÃ¶rlerini tÃ¼ret.

     b. **Associative Scan**: `k` tensÃ¶rÃ¼nden Î³ katsayÄ±larÄ±nÄ± tÃ¼ret ve **Associative Scan** fonksiyonunu kullanarak kÃ¼mÃ¼latif Ã§arpÄ±mÄ± hesapla: `cumprod = associative_scan_exponential(gamma)`

     c. **MDI (Memory Decay/Integration)**: `z_t` ve `h_{prev}`'yi kullanarak yeni bellek durumunu (`h_{t}` ve yeni Î³) hesapla: `h_new, gamma_new = mdi(z_t, h_prev)`

     d. **Core Formula**: `h_t = z_t âŠ™ Ïƒ(W_g h_{t-1}) + Î³ âŠ™ h_{t-1}` formÃ¼lÃ¼nÃ¼ uygula.

     e. **Multi-Memory Attention**: HDS'i kullanarak bellek sorgusunu yap: `mem_context = multi_mem_attention(h_t, hds, state)`

     f. **Residual ve Ã‡Ä±kÄ±ÅŸ**: Nihai Ã§Ä±ktÄ± tensÃ¶rÃ¼nÃ¼ ve gÃ¼ncellenmiÅŸ `MemoryState` nesnesini dÃ¶ndÃ¼r.

**Ek Notlar:**
- Core Formula: CORE_FORMULA_SPEC.md'deki formÃ¼lÃ¼ takip et
- Referans: CODE_STRUCTURE.md bÃ¶lÃ¼m 5 ve IMPLEMENTATION_SPEC.md bÃ¶lÃ¼m 4
- 7 adÄ±mÄ±n sÄ±rasÄ± kritik: ENGINEERING_OUTPUTS.md bÃ¶lÃ¼m 5.2
```

---

### 5. Multi-Memory Attention

**Dosya:** `mm_rec/blocks/attention.py`

**Prompt:**

```
MM-Rec modelinin Multi-Memory Attention mekanizmasÄ±nÄ± uygulamamÄ±z gerekiyor. Bu, O(LÂ²) yerine O(M) karmaÅŸÄ±klÄ±ÄŸÄ± ile uzun vadeli belleÄŸi sorgulayacak. LÃ¼tfen mm_rec/blocks/attention.py dosyasÄ±nÄ± oluÅŸtur.

**Gereksinimler:**

1. **MultiMemoryAttention SÄ±nÄ±fÄ±:** Bir PyTorch `nn.Module` olarak `MultiMemoryAttention` sÄ±nÄ±fÄ±nÄ± oluÅŸtur.

   * **__init__**: `model_dim`, `num_heads` ve `head_dim` parametrelerini almalÄ±.
   * **Multi-head attention**: Her head iÃ§in ayrÄ± query/key/value transformasyonlarÄ± tanÄ±mla.

2. **Sorgulama Fonksiyonu:** `forward(self, query: torch.Tensor, hds: HierarchicalDataStructure, state: MemoryState) -> torch.Tensor` metodunu oluÅŸtur.

   * **O(M) EriÅŸim**: `hds.query_memory(query, level=-1)` Ã§aÄŸrÄ±sÄ±nÄ± kullanarak hiyerarÅŸik bellekten (Ã¶rneÄŸin en Ã¼st seviye) **Key** ve **Value** tensÃ¶rlerini al. (KullanÄ±lacak bellek boyutunun $M \ll L$ olduÄŸunu varsay.)

   * **Dikkat SkorlarÄ± HesaplamasÄ±**: Sorgu (`query`, yani $h_t$) ile bellek Key'ler (`k_mem`) arasÄ±ndaki dikkat skorlarÄ±nÄ± hesapla: $\text{Skorlar} = Q \cdot K_{\text{mem}}^T / \sqrt{d_k}$.

   * **YumuÅŸak Maksimum (Softmax)**: Skorlara `softmax` uygula.

   * **BaÄŸlamsal VektÃ¶r**: SkorlarÄ± bellek Value'larla (`v_mem`) Ã§arp: $\text{Context} = \text{Softmax}(\text{Skorlar}) \cdot V_{\text{mem}}$.

   * **Geri DÃ¶nÃ¼ÅŸ**: Hesaplanan `Context` tensÃ¶rÃ¼nÃ¼ dÃ¶ndÃ¼r. Bu, MMRecBlock'ta Ã§Ä±ktÄ±ya eklenecektir.

**Ek Notlar:**
- Memory complexity: O(M) not O(NÂ²)
- Referans: IMPLEMENTATION_SPEC.md bÃ¶lÃ¼m 2.3 ve CODE_STRUCTURE.md bÃ¶lÃ¼m 4
- Multi-head attention pattern kullanÄ±lmalÄ±
```

---

## ğŸ‘‘ Faz 3: Model ve EÄŸitim

### 6. Complete Model

**Dosya:** `mm_rec/model.py`

**Prompt:**

```
ArtÄ±k tÃ¼m bileÅŸenlerimiz hazÄ±r. LÃ¼tfen mm_rec/model.py dosyasÄ±nÄ± oluÅŸturarak MM-Rec modelinin tam mimarisini oluÅŸtur.

**Gereksinimler:**

1. **MMRecModel SÄ±nÄ±fÄ±:** Bir PyTorch `nn.Module` olarak `MMRecModel` sÄ±nÄ±fÄ±nÄ± oluÅŸtur.

   * **__init__**: `vocab_size`, `model_dim`, `num_layers: int = 24`, `num_heads`, `num_memories`, `mem_dim`, `seq_len` gibi parametreleri almalÄ±.
   * **Embedding Layer**: GiriÅŸ belirteÃ§leri (token) iÃ§in `nn.Embedding` katmanÄ±nÄ± tanÄ±mla.
   * **MemoryState BaÅŸlatma**: BaÅŸlangÄ±Ã§ bellek durumu iÃ§in bir `MemoryState` Ã¶rneÄŸi oluÅŸtur.
   * **MM-Rec BloklarÄ±**: `nn.ModuleList` kullanarak 24 adet `MMRecBlock` katmanÄ±nÄ± baÅŸlat.
   * **Normalization**: Final RMSNorm katmanÄ±.
   * **Output Head**: Dil modelleme gÃ¶revi iÃ§in bir Ã§Ä±kÄ±ÅŸ lineer katmanÄ± (`nn.Linear`) tanÄ±mla.

2. **Ä°leri GeÃ§iÅŸ (Forward) Metodu:** `forward(self, input_ids: torch.Tensor) -> torch.Tensor` metodunu oluÅŸtur.

   * **GÃ¶mme (Embedding)**: `input_ids`'Ä± gÃ¶mme katmanÄ±ndan geÃ§ir.
   * **DÃ¶ngÃ¼**: TÃ¼m MMRecBlock katmanlarÄ± Ã¼zerinde dÃ¶ngÃ¼ kur. Her katmanda, hem girdi tensÃ¶rÃ¼nÃ¼ (`x`) hem de bellek durumunu (`state`) gÃ¼ncelle.
     * `x, state = block(x, state)`
   * Her katman iÃ§in ayrÄ± MemoryState kullanÄ±lmalÄ± (veya paylaÅŸÄ±lan state)
   * **Ã‡Ä±ktÄ± BaÅŸÄ±**: Nihai `x` tensÃ¶rÃ¼nÃ¼ normalize et ve Ã§Ä±kÄ±ÅŸ katmanÄ±ndan geÃ§ir.
   * **Geri DÃ¶nÃ¼ÅŸ**: Modelin `logits` Ã§Ä±ktÄ±larÄ±nÄ± dÃ¶ndÃ¼r.

**Ek Notlar:**
- Model configuration: 24 layers, 4096 hidden_dim, 32K+ seq_len (REQUIRED)
- Referans: CODE_STRUCTURE.md bÃ¶lÃ¼m 6 ve ENGINEERING_OUTPUTS.md bÃ¶lÃ¼m 5
- Memory state management: Her layer iÃ§in state gÃ¼ncellenmeli
```

---

## ğŸ“‹ Prompt KullanÄ±m KÄ±lavuzu

### AdÄ±m AdÄ±m KullanÄ±m

1. **SÄ±ralama**: Prompt'larÄ± sÄ±rayla kullanÄ±n (Faz 1 â†’ Faz 2 â†’ Faz 3)
2. **BaÄŸÄ±mlÄ±lÄ±klar**: Her prompt, Ã¶nceki prompt'larÄ±n tamamlanmasÄ±nÄ± gerektirir
3. **Test**: Her bileÅŸen oluÅŸturulduktan sonra test edin
4. **DokÃ¼mantasyon**: Her bileÅŸen iÃ§in docstring ekleyin

### LLM'e Verilecek Format

Her prompt'u LLM'e ÅŸu ÅŸekilde verin:

```
[PROMPT Ä°Ã‡ERÄ°ÄÄ°]

LÃ¼tfen bu prompt'u takip ederek [DOSYA_ADI] dosyasÄ±nÄ± oluÅŸtur.
Proje yapÄ±sÄ±na uygun olarak kod yaz.
Gerekli import'larÄ± ekle.
Docstring'leri ekle.
Test edilebilir kod yaz.
```

### DoÄŸrulama Checklist

Her bileÅŸen iÃ§in kontrol edin:

- [ ] Dosya doÄŸru konumda oluÅŸturuldu mu?
- [ ] Gerekli import'lar eklendi mi?
- [ ] Class/function signature'lar doÄŸru mu?
- [ ] Docstring'ler eklendi mi?
- [ ] Test edilebilir mi?
- [ ] Referans dokÃ¼mantasyonla uyumlu mu?

---

## ğŸ”— Ä°lgili DokÃ¼manlar

- **ENGINEERING_OUTPUTS.md**: TÃ¼m Ã§Ä±ktÄ±larÄ±n checklist'i
- **CODE_STRUCTURE.md**: API tasarÄ±mÄ± ve kod Ã¶rnekleri
- **IMPLEMENTATION_SPEC.md**: Algoritma detaylarÄ±
- **CORE_FORMULA_SPEC.md**: Core formula spesifikasyonu
- **PROJECT_STATUS.md**: Mevcut durum ve ilerleme

---

**Son GÃ¼ncelleme**: 2025-12-08
**Durum**: Prompt'lar hazÄ±r, implementasyon bekleniyor

