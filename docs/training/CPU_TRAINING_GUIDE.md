# MM-Rec 100M CPU EÄŸitim Rehberi

**Versiyon**: 1.0  
**Tarih**: 2025-12-08  
**Hedef**: CPU'da otomatik veri indirme ve eÄŸitim

---

## ğŸ¯ Genel BakÄ±ÅŸ

Bu rehber, MM-Rec 100M modelini **CPU'da** eÄŸitmek iÃ§in gereken tÃ¼m adÄ±mlarÄ± iÃ§erir. Sistem otomatik olarak:
1. Ä°nternetten veri indirir (WikiText, Code datasets)
2. Veriyi iÅŸler ve hazÄ±rlar
3. CPU'da eÄŸitime baÅŸlar

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### En Basit YÃ¶ntem (Tam Otomatik)

```bash
python3 -m mm_rec.scripts.auto_train
```

Bu komut:
- âœ… Veriyi otomatik indirir
- âœ… Veriyi iÅŸler
- âœ… CPU'da eÄŸitime baÅŸlar
- âœ… Checkpoint'leri kaydeder

### AdÄ±m AdÄ±m YÃ¶ntem

**1. Veri Ä°ndirme**:
```bash
python3 -m mm_rec.data.download_data \
    --output_dir ./data \
    --text_samples 500 \
    --code_samples 500
```

**2. CPU EÄŸitimi**:
```bash
python3 -m mm_rec.scripts.train_cpu \
    --stage stage1 \
    --batch_size 2 \
    --data_dir ./data \
    --download_data  # Veri yoksa otomatik indirir
```

---

## ğŸ“¥ Veri Ä°ndirme

### Desteklenen Kaynaklar

**Text Data**:
- **WikiText**: Wikipedia articles
- **The Pile**: Large text corpus
- **C4**: Common Crawl dataset

**Code Data**:
- **The Stack**: Large code dataset
- **Python Code**: Python-specific code
- **CodeSearchNet**: Code search dataset

### Veri Ä°ndirme KomutlarÄ±

**Sadece Text**:
```bash
python3 -m mm_rec.data.download_data \
    --text_samples 1000 \
    --no_code
```

**Sadece Code**:
```bash
python3 -m mm_rec.data.download_data \
    --code_samples 1000 \
    --no_wikitext
```

**Her Ä°kisi**:
```bash
python3 -m mm_rec.data.download_data \
    --text_samples 1000 \
    --code_samples 1000
```

### Ä°ndirilen Veri FormatÄ±

```
data/
â”œâ”€â”€ text/
â”‚   â””â”€â”€ wikitext.jsonl    # Her satÄ±r bir JSON string
â””â”€â”€ code/
    â””â”€â”€ code.jsonl        # Her satÄ±r bir JSON string
```

**Format**:
```json
"Bu bir Ã¶rnek metin..."
"def example_function(): ..."
```

---

## ğŸ–¥ï¸ CPU EÄŸitimi

### CPU OptimizasyonlarÄ±

**Otomatik Optimizasyonlar**:
- âœ… TÃ¼m CPU thread'leri kullanÄ±lÄ±r
- âœ… MKL optimizasyonlarÄ± aktif
- âœ… KÃ¼Ã§Ã¼k batch size (memory iÃ§in)
- âœ… KÄ±sa sekanslar (512 tokens)
- âœ… Gradient checkpointing (memory iÃ§in)

**Performans Ä°puÃ§larÄ±**:
```python
# CPU thread sayÄ±sÄ±nÄ± ayarla
torch.set_num_threads(os.cpu_count())

# MKL kullan
import mkl
mkl.set_num_threads(os.cpu_count())
```

### EÄŸitim KomutlarÄ±

**Stage 1 (Local Consistency)**:
```bash
python3 -m mm_rec.scripts.train_cpu \
    --stage stage1 \
    --batch_size 2 \
    --checkpoint_dir ./checkpoints_cpu \
    --data_dir ./data
```

**TÃ¼m Stage'ler**:
```bash
python3 -m mm_rec.scripts.train_cpu \
    --stage all \
    --batch_size 2 \
    --data_dir ./data
```

**Synthetic Data ile (HÄ±zlÄ± Test)**:
```bash
python3 -m mm_rec.scripts.train_cpu \
    --stage stage1 \
    --use_synthetic \
    --batch_size 2
```

### Beklenen Performans (CPU)

**SÃ¼re** (Stage 1, 1000 steps):
- Modern CPU (16 cores): ~2-4 saat
- Older CPU (8 cores): ~4-8 saat

**Memory**:
- Model: ~400 MB (FP32)
- Training: ~2-4 GB RAM
- Data: ~100-500 MB

**Throughput**:
- ~0.1-0.5 tokens/second (GPU: ~1000+ tokens/second)
- CPU eÄŸitimi GPU'dan **1000x daha yavaÅŸ**

---

## ğŸ“Š Monitoring

### CPU Training Monitoring

```python
# Training loop iÃ§inde
for step in range(num_steps):
    # ... training code ...
    
    # CPU utilization
    import psutil
    cpu_percent = psutil.cpu_percent(interval=1)
    print(f"CPU Usage: {cpu_percent}%")
    
    # Memory usage
    memory = psutil.virtual_memory()
    print(f"Memory: {memory.percent}%")
```

### Loss Tracking

```python
# Loss'u dosyaya kaydet
with open("loss_log.txt", "a") as f:
    f.write(f"{step},{loss.item()}\n")
```

---

## âš™ï¸ KonfigÃ¼rasyon

### CPU-Friendly Ayarlar

**Batch Size**:
- CPU iÃ§in: 1-2 (memory iÃ§in)
- GPU iÃ§in: 4-8

**Sequence Length**:
- CPU iÃ§in: 512 (hÄ±zlÄ± iterasyon)
- GPU iÃ§in: 8192+

**Max Steps**:
- CPU iÃ§in: 1000 (test iÃ§in)
- GPU iÃ§in: 5000-10000

**Checkpoint Interval**:
- CPU iÃ§in: 50 (sÄ±k kaydet)
- GPU iÃ§in: 100-200

### Ã–rnek KonfigÃ¼rasyon

```bash
python3 -m mm_rec.scripts.train_cpu \
    --stage stage1 \
    --batch_size 1 \
    --checkpoint_interval 25 \
    --max_samples 100 \
    --use_synthetic  # HÄ±zlÄ± test iÃ§in
```

---

## ğŸ”§ Sorun Giderme

### Sorun 1: Veri Ä°ndirme BaÅŸarÄ±sÄ±z

**Hata**: `ConnectionError` veya `Timeout`

**Ã‡Ã¶zÃ¼m**:
```bash
# Retry with timeout
python3 -m mm_rec.data.download_data \
    --text_samples 100 \
    --code_samples 100

# Veya synthetic data kullan
python3 -m mm_rec.scripts.train_cpu --use_synthetic
```

### Sorun 2: CPU Memory Yetersiz

**Hata**: `RuntimeError: out of memory`

**Ã‡Ã¶zÃ¼m**:
```bash
# Batch size'Ä± dÃ¼ÅŸÃ¼r
--batch_size 1

# Sequence length'i dÃ¼ÅŸÃ¼r
# (train_cpu.py iÃ§inde seq_len=256 yap)

# Max samples'Ä± azalt
--max_samples 50
```

### Sorun 3: Ã‡ok YavaÅŸ

**Sorun**: EÄŸitim Ã§ok yavaÅŸ

**Ã‡Ã¶zÃ¼m**:
- Synthetic data kullan (hÄ±zlÄ± test)
- Max steps'i azalt (100-200)
- Sadece Stage 1'i Ã§alÄ±ÅŸtÄ±r

### Sorun 4: Veri FormatÄ± HatasÄ±

**Hata**: `JSONDecodeError` veya `KeyError`

**Ã‡Ã¶zÃ¼m**:
```bash
# Veriyi yeniden indir
rm -rf ./data
python3 -m mm_rec.data.download_data

# Veya synthetic data kullan
python3 -m mm_rec.scripts.train_cpu --use_synthetic
```

---

## ğŸ“ Ã–rnek KullanÄ±m SenaryolarÄ±

### Senaryo 1: HÄ±zlÄ± Test (Synthetic)

```bash
# 5 dakikada test
python3 -m mm_rec.scripts.train_cpu \
    --stage stage1 \
    --use_synthetic \
    --batch_size 2 \
    --max_samples 10
```

### Senaryo 2: GerÃ§ek Veri ile EÄŸitim

```bash
# 1. Veri indir
python3 -m mm_rec.data.download_data \
    --text_samples 500 \
    --code_samples 500

# 2. EÄŸit
python3 -m mm_rec.scripts.train_cpu \
    --stage stage1 \
    --data_dir ./data \
    --batch_size 2
```

### Senaryo 3: Tam Otomatik

```bash
# Tek komutla her ÅŸey
python3 -m mm_rec.scripts.auto_train
```

---

## ğŸ“ Best Practices

### 1. CPU EÄŸitimi Ä°Ã§in

- âœ… KÃ¼Ã§Ã¼k batch size kullan (1-2)
- âœ… KÄ±sa sekanslar (512 tokens)
- âœ… SÄ±k checkpoint (her 25-50 step)
- âœ… Synthetic data ile test et
- âœ… Monitoring'i aktif tut

### 2. Veri Ä°ndirme Ä°Ã§in

- âœ… Ä°nternet baÄŸlantÄ±sÄ±nÄ± kontrol et
- âœ… Disk alanÄ±nÄ± kontrol et (500MB+)
- âœ… Hugging Face token gerekebilir (bÃ¼yÃ¼k dataset'ler iÃ§in)
- âœ… Ä°lk indirmede az sample al (test iÃ§in)

### 3. Production Ä°Ã§in

- âš ï¸ CPU eÄŸitimi **production iÃ§in Ã¶nerilmez**
- âœ… GPU kullan (1000x daha hÄ±zlÄ±)
- âœ… Distributed training (multi-GPU)
- âœ… Cloud GPU (AWS, GCP, Azure)

---

## ğŸ“Š Beklenen SonuÃ§lar

### CPU Training Metrics

**Stage 1** (1000 steps, CPU):
- SÃ¼re: ~2-4 saat
- Loss: 8-10 â†’ 3-4
- Memory: ~2-4 GB
- CPU Usage: ~80-100%

**GPU Training** (karÅŸÄ±laÅŸtÄ±rma):
- SÃ¼re: ~15-30 dakika
- Loss: 8-10 â†’ 2-3
- Memory: ~8-16 GB
- GPU Usage: ~90-100%

---

## ğŸš€ HÄ±zlÄ± Komutlar

### Tam Otomatik
```bash
python3 -m mm_rec.scripts.auto_train
```

### Veri Ä°ndir + EÄŸit
```bash
python3 -m mm_rec.scripts.train_cpu \
    --download_data \
    --stage stage1
```

### Synthetic Data ile Test
```bash
python3 -m mm_rec.scripts.train_cpu \
    --use_synthetic \
    --stage stage1 \
    --batch_size 2
```

---

## âš ï¸ Ã–nemli Notlar

1. **CPU EÄŸitimi YavaÅŸtÄ±r**: GPU'dan 1000x daha yavaÅŸ
2. **Test Ä°Ã§in**: CPU eÄŸitimi test ve geliÅŸtirme iÃ§in uygundur
3. **Production**: Production eÄŸitimi iÃ§in GPU kullanÄ±n
4. **Memory**: CPU'da memory sÄ±nÄ±rlÄ±, batch size kÃ¼Ã§Ã¼k tutun
5. **Veri**: Ä°nternet baÄŸlantÄ±sÄ± gereklidir

---

**Son GÃ¼ncelleme**: 2025-12-08  
**HazÄ±rlayan**: MM-Rec Development Team

